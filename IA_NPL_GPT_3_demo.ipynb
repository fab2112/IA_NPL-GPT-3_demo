{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IA_NPL_GPT-3_demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP+bLrFMM4Z7mU8o3nDk0s2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fab2112/IA_NPL-GPT-3_demo/blob/main/IA_NPL_GPT_3_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Demonstração de uso da API do modelo de linguagem natural GPT-3 da *openai*** \n",
        "Este notebook utiliza uma chave privada pessoal que deve ser obtida pelo cadastro no ambiente da *openai*. Após cadastro e obtenção da chave, com um editor de texto, copiar e colar a chave, salvando o arquivo como \"API_key.env\" em seu computador.\n",
        "\n",
        "https://openai.com/api/"
      ],
      "metadata": {
        "id": "bFbRdXJDTo4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**1 - Preparação**"
      ],
      "metadata": {
        "id": "FFumv5bYPdVO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.1 - Imports e Instalação de Bibliotecas**"
      ],
      "metadata": {
        "id": "bSk4q7sEVUFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colorama --quiet\n",
        "!pip install openai --quiet\n",
        "\n",
        "import os\n",
        "import openai\n",
        "from colorama import Fore\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "wIPSUOlVUqgo"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.2 - Carregamento da api-key e Instâncias Iniciais**"
      ],
      "metadata": {
        "id": "L75SKgMMXJUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()  # Carregamento do arquivo \"API_key.env\" com a chave pessoal salva\n",
        "openai.api_key_path = \"API_key.env\"\n",
        "openai.api_key = os.environ.get('OPENAI_KEY')\n",
        "completion = openai.Completion()"
      ],
      "metadata": {
        "id": "L6b5xl4NY1lR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.3 - Definição da Função de Requisição**"
      ],
      "metadata": {
        "id": "0N0BGRe_lz00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _request(prompt, engine=\"text-davinci-002\", temp=0, freq_pen=0, pres_pen=0, \n",
        "            best_of=1, max_tokens=100, top_p=1):\n",
        "    response = completion.create(\n",
        "        prompt=prompt,  # Dados de entrada\n",
        "        engine=engine,  # Modelo ajustado GPT-3\n",
        "        temperature=temp,  # Probabilidade de arriscar mais (0.9 - mais criativo))\n",
        "        frequency_penalty=freq_pen,  # Penalização de tokens baseado na frequência (-2.0 a 2.0)\n",
        "        presence_penalty=pres_pen,  # Penalização de tokens baseado na presença (-2.0 a 2.0)\n",
        "        best_of=best_of,  # Probabilidade logarítma de retorno das melhores conclusões\n",
        "        top_p=top_p,  # Similar ao parametro temperature\n",
        "        max_tokens=max_tokens)  # O número máximo de tokens a serem gerados na conclusão.\n",
        "    response = response.choices[0].text.strip()\n",
        "    return response"
      ],
      "metadata": {
        "id": "TL2QcS_AlxgW"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **2 - Exemplos de Utilização da IA com o Model de Linguagem Natural GPT-3**"
      ],
      "metadata": {
        "id": "OHOtIJT_aP8z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.1 - Perguntas e Respostas**"
      ],
      "metadata": {
        "id": "inQLKDgfae9_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(Fore.LIGHTCYAN_EX + \"\\nFaça uma pergunta para IA.\\n\" + Fore.RESET)\n",
        "count = 0\n",
        "while True:\n",
        "    try:\n",
        "        print(Fore.LIGHTYELLOW_EX + \"Humano:\" + Fore.RESET)\n",
        "        entrada = input()\n",
        "        print(Fore.BLUE + \"\\nResposta da IA:\\n\" + Fore.RESET + \n",
        "              _request(entrada, max_tokens=150) + \"\\n\")\n",
        "        count += 1\n",
        "    except KeyboardInterrupt:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKa9Gmdrn4Qv",
        "outputId": "ba4476f8-c939-49f0-e5bf-c59b97430cf8"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[96m\n",
            "Faça uma pergunta para IA.\n",
            "\u001b[39m\n",
            "\u001b[93mHumano:\u001b[39m\n",
            "O que é multverso?\n",
            "\u001b[34m\n",
            "Resposta da IA:\n",
            "\u001b[39mO multiverso é a teoria de que existem múltiplos universos paralelos, cada um com suas próprias leis físicas e constantes. A ideia do multiverso é uma extensão da teoria do big bang, que sugere que o universo se expandiu a partir de um ponto infinitamente denso e quente.\n",
            "\n",
            "\u001b[93mHumano:\u001b[39m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.2 - Traduções de Texto ou Palavras**"
      ],
      "metadata": {
        "id": "0OajqW6NtXGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(Fore.LIGHTCYAN_EX + \"\\nDigite uma palavra ou frase para a IA traduzir.\\n\" + Fore.RESET)\n",
        "while True:\n",
        "    try:\n",
        "        print(Fore.LIGHTYELLOW_EX + \"Lingua para traduzir:\" + Fore.RESET)\n",
        "        lingua = input()\n",
        "        print(Fore.LIGHTYELLOW_EX + \"Digite algo para traduzir:\" + Fore.RESET)\n",
        "        words = input()\n",
        "        prompt = \"traduza \" + words + \" into \" + lingua\n",
        "        print(Fore.BLUE + \"\\nTradução pela IA:\\n\" + Fore.RESET +\n",
        "              _request(prompt=prompt, temp=0.3, max_tokens=150) + \"\\n\")\n",
        "    except KeyboardInterrupt:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2SnJa2MpVNi",
        "outputId": "2016ce0f-a714-442f-8aa9-8c4ca867c3e5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[96m\n",
            "Digite uma palavra ou frase para a IA traduzir.\n",
            "\u001b[39m\n",
            "\u001b[93mLingua para traduzir:\u001b[39m\n",
            "english\n",
            "\u001b[93mDigite algo para traduzir:\u001b[39m\n",
            "O livro esta na mesa.\n",
            "\u001b[34m\n",
            "Tradução pela IA:\n",
            "\u001b[39mThe book is on the table.\n",
            "\n",
            "\u001b[93mLingua para traduzir:\u001b[39m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.3 - Listar Tópicos para Estudo** "
      ],
      "metadata": {
        "id": "hNy5CSGw-e8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(Fore.LIGHTCYAN_EX + \"\\nEscolha um assunto e pergunte a IA.\\n\" + Fore.RESET)\n",
        "while True:\n",
        "    try:\n",
        "        print(Fore.LIGHTYELLOW_EX + \"Sugestão de estudo:\" + Fore.RESET)\n",
        "        entrada = input()\n",
        "        prompt = \"Quais são 5 pontos chaves que deveria saber quando estudar \" + entrada + \" ?\"\n",
        "        print(Fore.BLUE + \"\\nTópicos sugeridos pela IA:\\n\" + Fore.RESET + \n",
        "              _request(prompt=prompt, temp=0.3, max_tokens=150) + \"\\n\")\n",
        "    except KeyboardInterrupt:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEDKtDTVqfEr",
        "outputId": "964f8194-e5c8-43cb-a1c7-f07d7f06c100"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[96m\n",
            "Escolha um assunto e pergunte a IA.\n",
            "\u001b[39m\n",
            "\u001b[93mSugestão de estudo:\u001b[39m\n",
            "Ciência de Dados\n",
            "\u001b[34m\n",
            "Tópicos sugeridos pela IA:\n",
            "\u001b[39m1. Ciência de Dados é a ciência da tomada de decisões.\n",
            "2. Ciência de Dados é a ciência do aprendizado.\n",
            "3. Ciência de Dados é a ciência da incerteza.\n",
            "4. Ciência de Dados é a ciência do futuro.\n",
            "5. Ciência de Dados é a ciência da vida.\n",
            "\n",
            "\u001b[93mSugestão de estudo:\u001b[39m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.4 - Criação de Perguntas** "
      ],
      "metadata": {
        "id": "_2XfJ5luIAk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(Fore.LIGHTCYAN_EX + \"\\nEscolha um assunto para formulação de perguntas pela IA.\\n\" + Fore.RESET)\n",
        "while True:\n",
        "    try:\n",
        "        print(Fore.LIGHTYELLOW_EX + \"Assunto:\" + Fore.RESET)\n",
        "        entrada = input()\n",
        "        prompt = \"Crie uma lista de 7 perguntas em português sobre o assunto \" + entrada\n",
        "        print(Fore.BLUE + \"\\nPerguntas geradas pela IA:\\n\" + Fore.RESET + \n",
        "              _request(prompt=prompt, temp=0.5, max_tokens=150) + \"\\n\")\n",
        "    except KeyboardInterrupt:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XSRrgirsPMD",
        "outputId": "d848b698-bb61-4fa2-e152-462e1aa6e24c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[96m\n",
            "Escolha um assunto para formulação de perguntas pela IA.\n",
            "\u001b[39m\n",
            "\u001b[93mAssunto:\u001b[39m\n",
            "Saturno\n",
            "\u001b[34m\n",
            "Perguntas geradas pela IA:\n",
            "\u001b[39m1. Qual é a massa de Saturno?\n",
            "2. Qual é o raio de Saturno?\n",
            "3. Qual é a densidade de Saturno?\n",
            "4. Qual é a temperatura média na superfície de Saturno?\n",
            "5. Qual é a composição atmosférica de Saturno?\n",
            "6. Qual é a rotação de Saturno?\n",
            "7. Qual é o período de revolução de Saturno?\n",
            "\n",
            "\u001b[93mAssunto:\u001b[39m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.5 - Correção Gramatical**\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "VvUkwVfiKfEW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(Fore.LIGHTCYAN_EX + \"\\nFormulue uma frase para ser corrigida pela IA.\\n\" + Fore.RESET)\n",
        "while True:\n",
        "    try:\n",
        "        print(Fore.LIGHTYELLOW_EX + \"Frase:\" + Fore.RESET)\n",
        "        entrada = input()\n",
        "        prompt = \"Corrigir isso no padrão da lingua portuguesa: \" + entrada\n",
        "        print(Fore.BLUE + \"\\nCorreção gerada pela IA:\\n\" + Fore.RESET + \n",
        "              _request(prompt=prompt, max_tokens=60, temp=0.3) + \"\\n\")\n",
        "    except KeyboardInterrupt:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Iq4XyR6s6Hq",
        "outputId": "5cafe143-2cf9-42b7-a350-79a8ace8c883"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[96m\n",
            "Formulue uma frase para ser corrigida pela IA.\n",
            "\u001b[39m\n",
            "\u001b[93mFrase:\u001b[39m\n",
            "o trem estão passando pela estações\n",
            "\u001b[34m\n",
            "Correção gerada pela IA:\n",
            "\u001b[39mO trem está passando pelas estações.\n",
            "\n",
            "\u001b[93mFrase:\u001b[39m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.6 - Classificação de Sentimento**"
      ],
      "metadata": {
        "id": "AZRZz7kRMgTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(Fore.LIGHTCYAN_EX + \"\\nEscreva uma frase ou palavra para a IA classificar o sentimento.\\n\" + Fore.RESET)\n",
        "while True:\n",
        "    try:\n",
        "        print(Fore.LIGHTYELLOW_EX + \"Frase:\" + Fore.RESET)\n",
        "        entrada = input()\n",
        "        prompt = \"Classificar a taxa de sentimento da frase:\\n\" + \"1. \" + entrada\n",
        "        print(Fore.BLUE + \"\\nClasse de sentimento gerada pela IA:\\n\" + Fore.RESET + \n",
        "              _request(prompt=prompt, max_tokens=60) + \"\\n\")\n",
        "    except KeyboardInterrupt:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hRbs1_ntyPL",
        "outputId": "e95fca11-cfa2-416c-d060-d03325fe7e04"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[96m\n",
            "Escreva uma frase ou palavra para a IA classificar o sentimento.\n",
            "\u001b[39m\n",
            "\u001b[93mFrase:\u001b[39m\n",
            "O bitcoin vai subir\n",
            "\u001b[34m\n",
            "Classe de sentimento gerada pela IA:\n",
            "\u001b[39mPositivo\n",
            "\n",
            "\u001b[93mFrase:\u001b[39m\n",
            "o bitcoin pode cair\n",
            "\u001b[34m\n",
            "Classe de sentimento gerada pela IA:\n",
            "\u001b[39mNegativo\n",
            "\n",
            "\u001b[93mFrase:\u001b[39m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.7 - Conversor de Terceira Pessoa**\n"
      ],
      "metadata": {
        "id": "CUbytLjRO-70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(Fore.LIGHTCYAN_EX + \"\\nFormlue uma frase para ser convertida pela IA.\\n\" + Fore.RESET)\n",
        "while True:\n",
        "    try:\n",
        "        print(Fore.LIGHTYELLOW_EX + \"Frase na primeira pessoa:\" + Fore.RESET)\n",
        "        entrada = input()\n",
        "        prompt = \"Converter a frase para terceira pessoa no masculino: \" + entrada\n",
        "        print(Fore.BLUE + \"\\nNa terceira pessoa gerada pela IA:\\n\" + \n",
        "              Fore.RESET + _request(prompt=prompt, max_tokens=60) + \"\\n\")\n",
        "    except KeyboardInterrupt:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuWKdMiZup1C",
        "outputId": "47ce20ed-e3fa-4455-8170-10c0fef9a368"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[96m\n",
            "Formlue uma frase para ser convertida pela IA.\n",
            "\u001b[39m\n",
            "\u001b[93mFrase na primeira pessoa:\u001b[39m\n",
            "Nós vamos viajar para uma bela cidade\n",
            "\u001b[34m\n",
            "Na terceira pessoa gerada pela IA:\n",
            "\u001b[39mEle vai viajar para uma bela cidade.\n",
            "\n",
            "\u001b[93mFrase na primeira pessoa:\u001b[39m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.8 - Completar Frases**\n"
      ],
      "metadata": {
        "id": "ounxaS6KfWT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(Fore.LIGHTCYAN_EX + \"\\nEscreva uma frase para ser complementada pela IA.\\n\" + Fore.RESET)\n",
        "while True:\n",
        "    try:\n",
        "        print(Fore.LIGHTYELLOW_EX + \"Frase para completar:\" + Fore.RESET)\n",
        "        entrada = input()\n",
        "        prompt = \"Crie uma analogia para esta frase: \" + entrada + \":\"\n",
        "        print(Fore.BLUE + \"\\nFrase análoga gerada pela IA:\\n\" + \n",
        "              Fore.RESET + _request(prompt=prompt, max_tokens=60, temp=0.5) + \"\\n\")\n",
        "    except KeyboardInterrupt:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im7nC_egfiGM",
        "outputId": "432e7dd2-ad0a-4ed4-af4b-1035c508e69c"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[96m\n",
            "Escreva uma frase para ser complementada pela IA.\n",
            "\u001b[39m\n",
            "\u001b[93mFrase para completar:\u001b[39m\n",
            "Hoje é um dia muito\n",
            "\u001b[34m\n",
            "Frase análoga gerada pela IA:\n",
            "\u001b[39mHoje é um dia muito especial.\n",
            "\n",
            "\u001b[93mFrase para completar:\u001b[39m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.9 - Formular Requisição SQL para Banco de Dados**"
      ],
      "metadata": {
        "id": "H_7qljvJh4gr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(Fore.LIGHTCYAN_EX + \"\\nEscreva uma frase para ser transformada pela IA no padão SQL.\\n\" + Fore.RESET)\n",
        "while True:\n",
        "    try:\n",
        "        print(Fore.LIGHTYELLOW_EX + \"Frase para transformar:\" + Fore.RESET)\n",
        "        entrada = input()\n",
        "        prompt = \"Crie uma requisição SQL para: \" + entrada + \":\"\n",
        "        print(Fore.BLUE + \"\\nFrase no padrão SQL gerada pela IA:\\n\" + \n",
        "              Fore.RESET + _request(prompt=prompt, max_tokens=60, temp=0.3) + \"\\n\")\n",
        "    except KeyboardInterrupt:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86v_hh1_iE9Z",
        "outputId": "dddc376e-f29a-430f-a257-296d77571f0e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[96m\n",
            "Escreva uma frase para ser transformada pela IA no padão SQL.\n",
            "\u001b[39m\n",
            "\u001b[93mFrase para transformar:\u001b[39m\n",
            "Separar todas as pessoas maiores de 18 que possuem habilitação e moram em São Paulo\n",
            "\u001b[34m\n",
            "Frase no padrão SQL gerada pela IA:\n",
            "\u001b[39mSELECT * FROM pessoas WHERE idade > 18 AND habilitacao = 'sim' AND cidade = 'São Paulo'\n",
            "\n",
            "\u001b[93mFrase para transformar:\u001b[39m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.10 - Selecionar Palavras-chave de Texto**"
      ],
      "metadata": {
        "id": "qxsvj8ENn8ew"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(Fore.LIGHTCYAN_EX + \"\\nEscreva um texto ou frase para a IA selecionar as palavras-chave\\n\" + Fore.RESET)\n",
        "while True:\n",
        "    try:\n",
        "        print(Fore.LIGHTYELLOW_EX + \"Texto para seleção:\" + Fore.RESET)\n",
        "        entrada = input()\n",
        "        prompt = \"Extrair palavras-chave do texto: \" + entrada + \":\"\n",
        "        print(Fore.BLUE + \"\\nPalavras-chave selecionadas pela IA:\\n\" + \n",
        "              Fore.RESET + _request(prompt=prompt, max_tokens=120, temp=0.3,\n",
        "                                    freq_pen=0.8) + \"\\n\")\n",
        "    except KeyboardInterrupt:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6X9mNVOn9kR",
        "outputId": "5be7873d-0788-40ab-b7bc-f06bc54aaf23"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[96m\n",
            "Escreva um texto ou frase para a IA selecionar as palavras-chave\n",
            "\u001b[39m\n",
            "\u001b[93mTexto para seleção:\u001b[39m\n",
            "A qualidade do texto gerado pelo GPT-3 é tão alta que é difícil distingui-lo daquele escrito por um humano, o que tem benefícios e riscos.\n",
            "\u001b[34m\n",
            "Palavras-chave selecionadas pela IA:\n",
            "\u001b[39m-GPT-3\n",
            "-texto gerado pelo GPT-3\n",
            "-qualidade do texto\n",
            "-benefícios\n",
            "-riscos\n",
            "\n",
            "\u001b[93mTexto para seleção:\u001b[39m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.11 - Conversão de Python em Outra Linguagem de Programação**"
      ],
      "metadata": {
        "id": "BswfnSveZDrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(Fore.LIGHTCYAN_EX + \"\\nEscreva um trecho de código em python para a IA converter\\n\" + Fore.RESET)\n",
        "while True:\n",
        "    try:\n",
        "        print(Fore.LIGHTYELLOW_EX + \"Linguagem para conversão:\" + Fore.RESET)\n",
        "        linguagem = input()\n",
        "        print(Fore.LIGHTYELLOW_EX + \"Trecho de código:\" + Fore.RESET)\n",
        "        entrada = input()\n",
        "        prompt = \"Converter o código em Python para \" + linguagem + \": \" + entrada\n",
        "        print(Fore.BLUE + \"\\nConversão em \" + linguagem +  \" pela IA:\\n\" + \n",
        "              Fore.RESET + _request(prompt=prompt, max_tokens=120) + \"\\n\")\n",
        "    except KeyboardInterrupt:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7An9aDJvZEV9",
        "outputId": "544ba91e-30fe-4bb0-c9f3-6b3c5b259de8"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[96m\n",
            "Escreva um trecho de código em python para a IA converter\n",
            "\u001b[39m\n",
            "\u001b[93mLinguagem para conversão:\u001b[39m\n",
            "C++\n",
            "\u001b[93mTrecho de código:\u001b[39m\n",
            "def func(a=0, b=1, c):   d = (a+ b) / c   return d \n",
            "\u001b[34m\n",
            "Conversão em C++ pela IA:\n",
            "\u001b[39mdouble func(double a = 0, double b = 1, double c) {\n",
            "    double d = (a + b) / c;\n",
            "    return d;\n",
            "}\n",
            "\n",
            "\u001b[93mLinguagem para conversão:\u001b[39m\n"
          ]
        }
      ]
    }
  ]
}